<div align="center">
  <img src="logo/logo.png" alt="Generate Logo" width="200"/>
</div>

<div align="center">
    <h1>Generate</h1>
    <p>
        A Python Package to Access World-Class Generative Models.
    </p>
    <p>
        <a href="https://wangyuxinwhy.github.io/generate/">ä¸­æ–‡æ–‡æ¡£</a>
        ï½œ
        <a href="https://colab.research.google.com/github/wangyuxinwhy/generate/blob/main/examples/tutorial.ipynb">äº¤äº’å¼æ•™ç¨‹</a>
    </p>

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](#)
[![CI Status](https://github.com/wangyuxinwhy/generate/actions/workflows/ci.yml/badge.svg)](https://github.com/wangyuxinwhy/generate/actions/workflows/ci.yml)
[![CD Status](https://github.com/wangyuxinwhy/generate/actions/workflows/cd.yml/badge.svg)](https://github.com/wangyuxinwhy/generate/actions/workflows/cd.yml)
[![License](https://img.shields.io/github/license/wangyuxinwhy/generate)](https://github.com/wangyuxinwhy/generate/blob/main/LICENSE)
[![Documentation](https://img.shields.io/badge/docs-latest-brightgreen.svg)](https://wangyuxinwhy.github.io/generate/)
[![Made with Love](https://img.shields.io/badge/made%20with-love-red.svg)](#)

</div>
<br>
<br>

# ç®€ä»‹



Generate å…è®¸ç”¨æˆ·é€šè¿‡ç»Ÿä¸€çš„ api è®¿é—®å¤šå¹³å°çš„ç”Ÿæˆå¼æ¨¡å‹ï¼Œå½“å‰æ”¯æŒï¼š

| å¹³å° ğŸ¤–           | åŒæ­¥ ğŸ”„ | å¼‚æ­¥ â³ | æµå¼ ğŸŒŠ | Vision ğŸ‘€ | Tools ğŸ› ï¸ |
| ----------------- | ------- | ------- | ------- | --------- | -------- |
| OpenAI            | âœ…      | âœ…      | âœ…      | âœ…        | âœ…       |
| Azure             | âœ…      | âœ…      | âŒ      | âœ…        | âœ…       |
| Anthropic         | âœ…      | âœ…      | âœ…      | âœ…        | âŒ       |
| æ–‡å¿ƒ Wenxin       | âœ…      | âœ…      | âœ…      | âŒ        | âœ…       |
| ç™¾ç‚¼ Bailian      | âœ…      | âœ…      | âœ…      | âŒ        | âŒ       |
| çµç§¯ DashScope    | âœ…      | âœ…      | âœ…      | âœ…        | âŒ       |
| ç™¾å·æ™ºèƒ½ Baichuan | âœ…      | âœ…      | âœ…      | âŒ        | âŒ       |
| Minimax           | âœ…      | âœ…      | âœ…      | âŒ        | âœ…       |
| æ··å…ƒ Hunyuan      | âœ…      | âœ…      | âœ…      | âŒ        | âŒ       |
| æ™ºè°± Zhipu        | âœ…      | âœ…      | âœ…      | âœ…        | âœ…       |
| æœˆä¹‹æš—é¢ Moonshot | âœ…      | âœ…      | âœ…      | âŒ        | âŒ       |
| DeepSeek          | âœ…      | âœ…      | âœ…      | âŒ        | âŒ       |
| é›¶ä¸€ä¸‡ç‰© Yi       | âœ…      | âœ…      | âœ…      | âœ…        | âŒ       |
| é˜¶è·ƒæ˜Ÿè¾° StepFun  | âœ…      | âœ…      | âœ…      | âœ…        | âŒ       |

## Features

- **å¤šæ¨¡æ€**ï¼Œæ”¯æŒæ–‡æœ¬ç”Ÿæˆï¼Œå¤šæ¨¡æ€æ–‡æœ¬ç”Ÿæˆï¼Œç»“æ„ä½“ç”Ÿæˆï¼Œå›¾åƒç”Ÿæˆï¼Œè¯­éŸ³ç”Ÿæˆ...
- **è·¨å¹³å°**ï¼Œæ”¯æŒ OpenAIï¼ŒAzureï¼ŒMinimaxï¼Œæ™ºè°±ï¼Œæœˆä¹‹æš—é¢ï¼Œæ–‡å¿ƒä¸€è¨€ åœ¨å†…çš„å›½å†…å¤– 10+ å¹³å°
- **One API**ï¼Œç»Ÿä¸€äº†ä¸åŒå¹³å°çš„æ¶ˆæ¯æ ¼å¼ï¼Œæ¨ç†å‚æ•°ï¼Œæ¥å£å°è£…ï¼Œè¿”å›è§£æï¼Œè®©ç”¨æˆ·æ— éœ€å…³å¿ƒä¸åŒå¹³å°çš„å·®å¼‚
- **å¼‚æ­¥ï¼Œæµå¼å’Œå¹¶å‘**ï¼Œæä¾›æµå¼è°ƒç”¨ï¼Œéæµå¼è°ƒç”¨ï¼ŒåŒæ­¥è°ƒç”¨ï¼Œå¼‚æ­¥è°ƒç”¨ï¼Œå¼‚æ­¥æ‰¹é‡å¹¶å‘è°ƒç”¨ï¼Œé€‚é…ä¸åŒçš„åº”ç”¨åœºæ™¯
- **è‡ªå¸¦ç”µæ± **ï¼Œæä¾› chainlit UIï¼Œè¾“å…¥æ£€æŸ¥ï¼Œå‚æ•°æ£€æŸ¥ï¼Œè®¡è´¹ï¼Œé€Ÿç‡æ§åˆ¶ï¼Œ_Agent_, _Tool call_ ç­‰
- **è½»é‡**ï¼Œæœ€å°åŒ–ä¾èµ–ï¼Œä¸åŒå¹³å°çš„è¯·æ±‚å’Œé‰´æƒé€»è¾‘å‡ä¸ºåŸç”Ÿå†…ç½®åŠŸèƒ½
- **é«˜è´¨é‡ä»£ç **ï¼Œ100% typehintsï¼Œpylance strict, ruff lint & format, test coverage > 85% ...

## åŸºç¡€ä½¿ç”¨

<a target="_blank" href="https://colab.research.google.com/github/wangyuxinwhy/generate/blob/main/examples/tutorial.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

### å®‰è£…

```bash
pip install generate-core
```

### æŸ¥çœ‹æ¨¡å‹åˆ—è¡¨

```python
from generate.chat_completion import ChatModelRegistry

print('\n'.join([model_cls.__name__ for model_cls, _ in ChatModelRegistry.values()]))

# ----- Output -----
AzureChat
AnthropicChat
OpenAIChat
MinimaxProChat
MinimaxChat
ZhipuChat
ZhipuCharacterChat
WenxinChat
HunyuanChat
BaichuanChat
BailianChat
DashScopeChat
DashScopeMultiModalChat
MoonshotChat
DeepSeekChat
YiChat
```

### é…ç½®æ¨¡å‹ API

```python
from generate import WenxinChat

# è·å–å¦‚ä½•é…ç½®æ–‡å¿ƒä¸€è¨€ï¼Œå…¶ä»–æ¨¡å‹åŒç†
print(WenxinChat.how_to_settings())

# ----- Output -----
WenxinChat Settings

# Platform
Qianfan

# Required Environment Variables
['QIANFAN_API_KEY', 'QIANFAN_SECRET_KEY']

# Optional Environment Variables
['QIANFAN_PLATFORM_URL', 'QIANFAN_COMLPETION_API_BASE', 'QIANFAN_IMAGE_GENERATION_API_BASE', 'QIANFAN_ACCESS_TOKEN_API']

You can get more information from this link: https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Dlkm79mnx

tips: You can also set these variables in the .env file, and generate will automatically load them.
```

### å¯¹è¯è¡¥å…¨æ¨¡å‹

#### æ–‡æœ¬ç”Ÿæˆ

```python
from generate import OpenAIChat

model = OpenAIChat()
model.generate('ä½ å¥½ï¼ŒGPTï¼', temperature=0, seed=2023)

# ----- Output -----
ChatCompletionOutput(
    model_info=ModelInfo(task='chat_completion', type='openai', name='gpt-3.5-turbo-0613'),
    cost=0.000343,
    extra={'usage': {'prompt_tokens': 13, 'completion_tokens': 18, 'total_tokens': 31}},
    message=AssistantMessage(
        role='assistant',
        name=None,
        content='ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ',
        function_call=None,
        tool_calls=None
    ),
    finish_reason='stop'
)
```

#### å¤šæ¨¡æ€æ–‡æœ¬ç”Ÿæˆ

```python
from generate import OpenAIChat

model = OpenAIChat(model='gpt-4-vision-preview')
user_message = {
    'role': 'user',
    'content': [
        {'text': 'è¿™ä¸ªå›¾ç‰‡æ˜¯å“ªé‡Œï¼Ÿ'},
        {'image_url': {'url': 'https://dashscope.oss-cn-beijing.aliyuncs.com/images/dog_and_girl.jpeg'}},
    ],
}
model.generate(user_message, max_tokens=1000)

# ----- Output -----
ChatCompletionOutput(
    model_info=ModelInfo(task='chat_completion', type='openai', name='gpt-4-1106-vision-preview'),
    cost=0.10339000000000001,
    extra={'usage': {'prompt_tokens': 1120, 'completion_tokens': 119, 'total_tokens': 1239}},
    message=AssistantMessage(
        role='assistant',
        name=None,
        content='è¿™å¼ å›¾ç‰‡æ˜¾ç¤ºçš„æ˜¯ä¸€åå¥³å£«å’Œä¸€åªç‹—åœ¨æ²™æ»©ä¸Šã€‚ä»–ä»¬ä¼¼ä¹åœ¨äº«å—æ—¥è½æ—¶åˆ†çš„å®é™æ—¶åˆ»',
        function_call=None,
        tool_calls=None
    ),
    finish_reason='stop'
)
```

### æ´¾ç”ŸåŠŸèƒ½

#### ç»“æ„ä½“ç”Ÿæˆ

```python
from generate import OpenAIChat
from pydantic import BaseModel

class Country(BaseModel):
    name: str
    capital: str

model = OpenAIChat().structure(output_structure_type=Country)
model.generate('Paris is the capital of France and also the largest city in the country.')
# ----- Output -----
StructureModelOutput(
    model_info=ModelInfo(task='chat_completion', type='openai', name='gpt-3.5-turbo-0613'),
    cost=0.000693,
    extra={'usage': {'prompt_tokens': 75, 'completion_tokens': 12, 'total_tokens': 87}},
    structure=Country(name='France', capital='Paris')
)
```

#### é€Ÿç‡é™åˆ¶

```python
import time
from generate import OpenAIChat

# é™åˆ¶é€Ÿç‡ï¼Œæ¯ 10 ç§’æœ€å¤š 4 æ¬¡è¯·æ±‚
limit_model = OpenAIChat().limit(max_generates_per_time_window=2, num_seconds_in_time_window=10)
start_time = time.time()
for i in limit_model.batch_generate([f'1 + {i} = ?' for i in range(4)]):
    print(i.reply)
    print(f'elapsed time: {time.time() - start_time:.2f} seconds')

# ----- Output -----
1
elapsed time: 0.70 seconds
2
elapsed time: 1.34 seconds
3
elapsed time: 11.47 seconds
4
elapsed time: 12.15 seconds
```

#### å¯¹è¯å†å²ä¿æŒ

```python
from generate import OpenAIChat

session_model = OpenAIChat().session()
session_model.generate('i am bob')
print(session_model.generate('What is my name?').reply)

# ----- Output -----
Your name is Bob.
```

#### å·¥å…·è°ƒç”¨

```python
from generate import OpenAIChat, tool

@tool
def get_weather(location: str) -> str:
    return f'{location}, 27Â°C, Sunny'

agent = OpenAIChat().agent(tools=get_weather)
print(agent.generate('what is the weather in Beijing?').reply)

# ----- Output -----
The weather in Beijing is currently 27Â°C and sunny.
```

### å›¾åƒç”Ÿæˆæ¨¡å‹

```python
from generate import OpenAIImageGeneration

model = OpenAIImageGeneration()
model.generate('black hole')

# ----- Output -----
ImageGenerationOutput(
    model_info=ModelInfo(task='image_generation', type='openai', name='dall-e-3'),
    cost=0.56,
    extra={},
    images=[
        GeneratedImage(
            url='https://oaidalleapiprodscus.blob.core.windows.net/...',
            prompt='Visualize an astronomical illustration featuring a black hole at its core. The black hole
should be portrayed with strong gravitational lensing effect that distorts the light around it. Include a
surrounding accretion disk, glowing brightly with blue and white hues, streaked with shades of red and orange,
indicating heat and intense energy. The cosmos in the background should be filled with distant stars, galaxies, and
nebulas, illuminating the vast, infinite space with specks of light.',
            image_format='png',
            content=b'<image bytes>'
        )
    ]
)
```

### è¯­éŸ³ç”Ÿæˆæ¨¡å‹

```python
from generate import MinimaxSpeech

model = MinimaxSpeech()
model.generate('ä½ å¥½ï¼Œä¸–ç•Œï¼')

# ----- Output -----
TextToSpeechOutput(
    model_info=ModelInfo(task='text_to_speech', type='minimax', name='speech-01'),
    cost=0.01,
    extra={},
    audio=b'<audio bytes>',
    audio_format='mp3'
)
```

### å¤šç§è°ƒç”¨æ–¹å¼

```python
from generate import OpenAIChat

model = OpenAIChat()
for stream_output in model.stream_generate('ä»‹ç»ä¸€ä¸‹å”æœ'):
    print(stream_output.stream.delta, end='', flush=True)

# åŒæ­¥è°ƒç”¨ï¼Œmodel.generate
# å¼‚æ­¥è°ƒç”¨ï¼Œmodel.async_generate
# æµå¼è°ƒç”¨ï¼Œmodel.stream_generate
# å¼‚æ­¥æµå¼è°ƒç”¨ï¼Œmodel.async_stream_generate
# æ‰¹é‡è°ƒç ”ï¼Œmodel.batch_generate
# å¼‚æ­¥æ‰¹é‡è°ƒç”¨ï¼Œmodel.async_batch_generate
```

### å¯åŠ¨ chainlit UI

```bash
python -m generate.ui
# help
# python -m generate.ui --help
```
