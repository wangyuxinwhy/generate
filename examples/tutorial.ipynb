{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate\n",
    "\n",
    "ğŸ‘ğŸ» æ¬¢è¿æ¥åˆ° Generate çš„æ•™ç¨‹ï¼Œåœ¨è¿™é‡Œæ‚¨å°†å­¦ä¹ åˆ°ï¼š\n",
    "\n",
    "1. ä½¿ç”¨ç»Ÿä¸€ç®€æ´çš„ API æ›¿ä»£ä¸åŒå¹³å°æ‚ä¹±çš„ SDK\n",
    "2. ä½¿ç”¨ `Generate` ç”Ÿæˆæ–‡æœ¬ï¼Œå›¾åƒä»¥åŠéŸ³é¢‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åšç‚¹å°å°çš„å‡†å¤‡å·¥ä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬ä¸€æ­¥ï¼Œå®‰è£… `generate-core` ğŸ˜‰\n",
    "!pip install generate-core\n",
    "# é¡ºä¾¿å®‰è£…ä¸€ä¸‹ rich ç¾åŒ–è¾“å‡º\n",
    "!pip install rich "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`generate-core` å·²ç»å®‰è£…å®Œæˆäº†ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹èƒ½ä¸èƒ½æ­£ç¡®çš„å¼•ç”¨ `generate` åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import generate\n",
    "    import rich\n",
    "except ImportError as e:\n",
    "    raise ValueError(\"æ²¡æœ‰æ‰§è¡Œ !pip install generate-core å’Œ rich å—ï¼Ÿ\") from e\n",
    "else:\n",
    "    print(\"ä¸€åˆ‡éƒ½åœ¨è®¡åˆ’ä¹‹å†…ï¼Œå®‰è£…æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é…ç½® OpenAI Key\n",
    "\n",
    "åœ¨ä½¿ç”¨ `generate` ä¹‹å‰ï¼Œéœ€è¦å…ˆé…ç½® OpenAI API Keyï¼Œè¿™æ ·æ‰èƒ½ä½¿ç”¨ OpenAI çš„ APIã€‚ \n",
    "\n",
    "`generate` åº“ä½¿ç”¨ [Pydantic Settings](https://docs.pydantic.dev/latest/concepts/pydantic_settings/) ç®¡ç†ä¸åŒå¹³å°çš„é…ç½®ï¼ŒPydantic Settings ä¼šä» `.env` æ–‡ä»¶ï¼Œç¯å¢ƒå˜é‡æˆ–è€… **è¿è¡Œæ—¶** è·å–ç›¸å…³é…ç½®ã€‚\n",
    "\n",
    "ä¸è¿‡ï¼Œæˆ‘ä»¬å…ˆä¸ç®¡è¿™ä¹ˆå¤šï¼Œå°±å…ˆé€šè¿‡ç¯å¢ƒå˜é‡æ¥å®Œæˆé…ç½®å§ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-*****'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹é…ç½®æ˜¯å¦ç”Ÿæ•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate.platforms import OpenAISettings\n",
    "from pydantic import ValidationError\n",
    "\n",
    "try:\n",
    "    OpenAISettings()  # type: ignore\n",
    "except ValidationError as e:\n",
    "    raise ValueError(\"æ²¡æœ‰è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡å—ï¼Ÿ\") from e\n",
    "else:\n",
    "    print(\"å¥½çš„ï¼çƒ­èº«å®Œæ¯•ï¼Œä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œä¸‹é¢è®©æˆ‘ä»¬æ­£å¼å¼€å§‹ ğŸš€ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatCompletion æ–‡æœ¬ç”Ÿæˆ\n",
    "\n",
    "åœ¨ `generate` åº“ä¸­ï¼Œæ— è®ºæ˜¯æ–‡æœ¬ç”Ÿæˆï¼Œå›¾åƒç”Ÿæˆï¼Œè¿˜æ˜¯è¯­éŸ³ç”Ÿæˆã€‚ä»–ä»¬éµå¾ªçš„éƒ½æ˜¯ç›¸åŒçš„ä½¿ç”¨é€»è¾‘\n",
    "1. åˆå§‹åŒ–ç”Ÿæˆæ¨¡å‹\n",
    "   - [å¯é€‰] é€‰æ‹©æ¨¡å‹å‹å·\n",
    "   - [å¯é€‰] è®¾ç½®é»˜è®¤çš„æ¨¡å‹å‚æ•°\n",
    "2. ä½¿ç”¨ `generate` æ–¹æ³•æ¥è°ƒç”¨æ¨¡å‹\n",
    "   - [å¿…é€‰] è®¾ç½® prompt, å¯¹äº ChatCompletion æ¥è¯´ï¼Œprompt ä¸€èˆ¬å°±æ˜¯æ–‡æœ¬\n",
    "   - [å¯é€‰] è®¾ç½®æ­¤æ¬¡è°ƒç”¨çš„æ¨¡å‹å‚æ•°\n",
    "3. è·å–æ¨¡å‹è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŸºç¡€ä½¿ç”¨\n",
    "æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼å°±æ˜¯åƒä¸‹é¢è¿™æ ·ï¼Œåªæ§åˆ¶ promptï¼Œå…¶ä»–éƒ½ä½¿ç”¨é»˜è®¤å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import OpenAIChat\n",
    "\n",
    "model = OpenAIChat()\n",
    "model_output = model.generate('ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±')\n",
    "\n",
    "rich.print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹è¾“å‡ºäº†ä¸€ä¸ªç»“æ„åŒ–çš„å¯¹è±¡ `ChatCompletionOutput`ï¼Œå…¶ä¸­åŒ…æ‹¬äº†ä¸€äº›æœ‰ç”¨çš„ä¿¡æ¯ï¼Œæ¯”å¦‚ï¼š\n",
    "- æ¨¡å‹ä¿¡æ¯ï¼Œåœ¨ model_info å­—æ®µä¸­ï¼ŒåŒ…å«äº†ä»»åŠ¡ç§ç±»ï¼Œå¹³å°ä»¥åŠæ¨¡å‹åç§°\n",
    "- ç”Ÿæˆæ¶ˆæ¯ï¼Œåœ¨ messages å­—æ®µä¸­ï¼ŒåŒ…å«äº† gpt æ¨¡å‹ç”Ÿæˆçš„æ¶ˆæ¯\n",
    "- è®¡è´¹ä¿¡æ¯ï¼Œåœ¨ cost å­—æ®µä¸­ï¼ŒåŒ…å«äº†æ­¤æ¬¡ä»»åŠ¡çš„èŠ±é”€ï¼Œå•ä½æ˜¯å…ƒ\n",
    "- ç»“æŸåŸå› ï¼Œåœ¨ finish_reason å­—æ®µä¸­ï¼Œå±•ç¤ºäº†æ­¤æ¬¡ä»»åŠ¡å®Œæˆçš„åŸå› \n",
    "- é¢å¤–ä¿¡æ¯ï¼Œåœ¨ extra å­—æ®µä¸­ï¼ŒåŒ…å«äº†ä¸€äº›å¯èƒ½ä¼šæœ‰ç”¨çš„é¢å¤–ä¿¡æ¯ï¼Œæ¯”å¦‚æ­¤æ¬¡ä»»åŠ¡ä½¿ç”¨äº†å¤šå°‘ token ç­‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ChatCompletionOutput` å¯¹è±¡çš„åŸºç±»æ˜¯ [Pydantic BaseModel](https://docs.pydantic.dev/latest/concepts/models/)ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¿é—®å±æ€§çš„æ–¹å¼è®¿é—®è¿™äº›å­—æ®µã€‚\n",
    "\n",
    "é™¤æ­¤ä¹‹å¤–ï¼Œ`ChatCompletionOutput` è¿˜æä¾›äº†ä¸€äº›å¸¸ç”¨çš„è®¡ç®—å±æ€§ï¼Œæ¯”å¦‚ `reply` å’Œ `last_message`ã€‚å°±åƒä¸‹é¢è¿™æ ·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = model_output.cost\n",
    "reply = model_output.reply\n",
    "last_message = model_output.last_message\n",
    "rich.print(f'{cost=}')\n",
    "rich.print(f'{reply=}')\n",
    "rich.print(f'{last_message=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è®¾ç½®æ¨¡å‹åŠå…¶å‚æ•°\n",
    "\n",
    "å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä¸ä½¿ç”¨é»˜è®¤çš„æ¨¡å‹å’Œå‚æ•°ï¼Œè€Œæ˜¯è‡ªå®šä¹‰ä»–ä»¬ã€‚\n",
    "\n",
    "æ¨¡å‹çš„å‚æ•°å¯ä»¥åœ¨æ¨¡å‹åˆå§‹åŒ–çš„æ—¶å€™è®¾ç½®ï¼Œä»¥ä½œä¸ºæ¨¡å‹çš„é»˜è®¤å‚æ•°ã€‚ä¹Ÿå¯ä»¥åœ¨è°ƒç”¨ `generate` æ–¹æ³•çš„æ—¶å€™è®¾ç½®ï¼Œä»¥ä½œä¸ºæ­¤æ¬¡è°ƒç”¨çš„å‚æ•°ã€‚\n",
    "\n",
    "- åˆå§‹åŒ–æ—¶çš„å‚æ•°ï¼Œå¿…é¡»æ˜¾å¼å£°æ˜ï¼Œä»¥ `OpenAIChat` ä¸ºä¾‹ï¼Œå®ƒçš„å‚æ•°ä¸º `OpenAIChatParameters` å®ä¾‹ã€‚\n",
    "- è°ƒç”¨æ—¶çš„å‚æ•°ï¼Œæ— é¡»æ˜¾å¼å£°æ˜ï¼Œç›´æ¥ä¼ å…¥å…³é”®å­—å‚æ•°å³å¯ï¼Œæ¯”å¦‚ `model.generate('ä½ å¥½', temperature=0.5)`\n",
    "  \n",
    "`generate` åŒ…ä¸­çš„å‘½åéµå¾ªå›ºå®šçš„åŸåˆ™ï¼Œä»»ä½•æ¨¡å‹å‚æ•°çš„ç±»åï¼Œéƒ½æ˜¯æ¨¡å‹åç§° + Parameters\n",
    "- OpenAIChat -> OpenAIChatParameters\n",
    "- MinimaxChat -> MinimaxChatParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import OpenAIChat, OpenAIChatParameters\n",
    "\n",
    "\n",
    "model_parameters = OpenAIChatParameters(top_p=0.85) # æ˜¾å¼å£°æ˜æ¨¡å‹å‚æ•°\n",
    "model = OpenAIChat(model='gpt-4', parameters=model_parameters) # ä½¿ç”¨ GPT-4 æ¨¡å‹\n",
    "model_output = model.generate('ä½ å¥½', temperature=0.9) # è°ƒç”¨æ—¶ä¼ å…¥ temperature å‚æ•°\n",
    "rich.print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æµå¼è¾“å‡º\n",
    "\n",
    "åœ¨ `generate` æ–¹æ³•å‰åŠ ä¸Š streamï¼Œä¹Ÿå°±æ˜¯ `stream_generate` ï¼Œå°±å˜æˆäº†æµå¼è¾“å‡ºï¼`stream_generate` è¿”å›ä¸€ä¸ªç”Ÿäº§å™¨ï¼Œä½ å¯ä»¥é€šè¿‡ for å¾ªç¯æ¥è¿­ä»£å®ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_output = next(model.stream_generate('ä½ å¥½'))\n",
    "rich.print(stream_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yield çš„å¯¹è±¡æ˜¯ `ChatCompletionStreamOutput`ï¼Œå®ƒåªæ˜¯åœ¨ `ChatCompletionOutput` çš„åŸºç¡€ä¸Šå¢åŠ äº†ä¸€ä¸ª stream å­—æ®µï¼Œå…¶ä¸­ delta ä»£è¡¨æ¯æ¬¡ç”Ÿäº§çš„å°ç‰‡æ®µï¼Œcontrol æ ‡è¯†äº†æ§åˆ¶ä¿¡æ¯ã€‚\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬å®Œæ•´çš„çœ‹ä¸€ä¸‹æµå¼è¾“å‡ºçš„ä¾‹å­å§ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIChat()\n",
    "finish_output = None\n",
    "for output in model.stream_generate('ä»‹ç»ä¸€ä¸‹ä¸‰ä½“ä¸­çš„ä¸»è¦äººç‰©'):\n",
    "    print(output.stream.delta, flush=True, end='')\n",
    "    if output.stream.control == 'finish':\n",
    "        finish_output = output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich.print(finish_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œcontrol ä¸º finish çš„ `ChatCompletionStreamOutput` ä¸­ä¾ç„¶åŒ…å«äº†å„ç§æœ‰ç”¨çš„ä¿¡æ¯ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¤šè½®å¯¹è¯\n",
    "\n",
    "\n",
    "ä¸Šé¢ä»‹ç»çš„ä¾‹å­éƒ½æ˜¯å•è½®å¯¹è¯ï¼Œè€Œä¸”ä¹Ÿåªæ¶‰åŠåˆ°æ–‡æœ¬ï¼Œå¹¶ä¸æ¶‰åŠåˆ° FunctionCallï¼Œå¤šæ¨¡æ€å¯¹è¯ç­‰ã€‚\n",
    "\n",
    "è¿™éƒ¨åˆ†çš„å†…å®¹å°†åœ¨è¿›é˜¶ä½¿ç”¨ä¸­è¯¦ç»†ä»‹ç»ï¼Œä¸‹é¢æˆ‘ä»¬åªç»™ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    [\n",
    "        {'role': 'user', 'content': 'ä½ å¥½ï¼ŒGPTï¼'},\n",
    "        {'role': 'assistant', 'content': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'},\n",
    "        {'role': 'user', 'content': 'é‡å¤æˆ‘çš„ç¬¬ä¸€å¥è¯'},\n",
    "    ]\n",
    ")\n",
    "output.reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¾“å…¥åŠå‚æ•°æ£€æŸ¥\n",
    "\n",
    "`generate` åŒ…ä¼šå¯¹ä½ æŒ‡å®šçš„æ¨¡å‹å‚æ•°è¿›è¡Œæå‰æ£€æŸ¥\n",
    "\n",
    "temperature å‚æ•°çš„å–å€¼èŒƒå›´æ˜¯ 0 åˆ° 1ï¼Œå¦‚æœä½ ä¼ å…¥äº†ä¸€ä¸ªä¸åˆæ³•çš„å€¼ï¼Œé‚£ä¹ˆ `generate` ä¼šæŠ›å‡ºä¸€ä¸ªå¼‚å¸¸ï¼Œå¹¶å‘Šè¯‰ä½  temperature å‚æ•°çš„å–å€¼èŒƒå›´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate('ä½ å¥½', temperature=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­å–œ ğŸ‰ï¼Œä½ å·²ç»å­¦ä¼šäº† OpenAIChat çš„åŸºç¡€ä½¿ç”¨ã€‚\n",
    "\n",
    "æŒæ¡äº† OpenAIChat åï¼Œä½ ä¹ŸåŒæ ·æŒæ¡äº† `generate` æ”¯æŒçš„æ‰€æœ‰èŠå¤©æ¨¡å‹ï¼Œä»–ä»¬çš„ä½¿ç”¨æ–¹å¼ä¸€æ¨¡ä¸€æ ·ï¼\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹ï¼Œä½ çš„å·¥å…·ç®±é‡Œé¢è¿˜æœ‰å“ªäº›æ­¦å™¨å§~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate.chat_completion import ChatModels\n",
    "\n",
    "model_names = [model.__name__ for model, _ in ChatModels]\n",
    "\n",
    "print(f'ä»¥ä¸‹çš„æ¨¡å‹éƒ½å¯ä»¥é€šè¿‡å’Œ OpenAIChat ä¸€æ ·çš„æ–¹å¼ä½¿ç”¨ï¼š')\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One More Thing\n",
    "\n",
    "\n",
    "é™¤äº† `generate.chat_completion` æ¨¡å‹å¤–ï¼Œ`generate` è¿˜æ”¯æŒ `generate.image_generation` å’Œ `generate.text_to_speech` æ¨¡å‹ã€‚\n",
    "\n",
    "\n",
    "è€Œä¸”ï¼Œä»–ä»¬çš„ä½¿ç”¨æ–¹å¼ä¹Ÿå’Œ `generate.chat_completion` ä¸€æ¨¡ä¸€æ ·ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, Image\n",
    "from generate import OpenAISpeech\n",
    "\n",
    "model = OpenAISpeech()\n",
    "speech_output = model.generate('ä½ å¥½ï¼Œä¸–ç•Œï¼')\n",
    "Audio(speech_output.audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import OpenAIImageGeneration\n",
    "\n",
    "model = OpenAIImageGeneration(model='dall-e-2')\n",
    "image_output = model.generate('ä¸€åªå¯çˆ±çš„çŒ«')\n",
    "Image(image_output.images[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŸºç¡€ä½¿ç”¨æ•™ç¨‹å·²ç»ç»“æŸå•¦ï¼ğŸŒŸ å¦‚æœä½ æƒ³æ·±å…¥äº†è§£æ›´å¤šç²¾å½©å†…å®¹ï¼Œå¯ä»¥ç»§ç»­æ¢ç´¢æˆ‘ä»¬çš„è¿›é˜¶ä½¿ç”¨æ•™ç¨‹ã€ä¸°å¯Œçš„åº”ç”¨ç¤ºä¾‹ï¼Œæˆ–è€…æ·±å…¥é˜…è¯» `Generate` æ–‡æ¡£ï¼\n",
    "\n",
    "ğŸ‘©â€ğŸ’» å¯¹äºä»¥ä¸‹è®®é¢˜æ„Ÿå…´è¶£çš„æœ‹å‹ï¼Œè¯·å‚è€ƒæˆ‘ä»¬çš„[è¿›é˜¶ä½¿ç”¨æ•™ç¨‹](https://colab.research.google.com/github/wangyuxinwhy/generate/blob/main/examples/advanced_usage.ipynb)ï¼š\n",
    "1. å¼‚æ­¥è°ƒç”¨ `model.async_generate` å’Œå¼‚æ­¥æµå¼è°ƒç”¨ `model.async_stream_generate`\n",
    "2. è®¾å®šçµæ´»çš„é‡è¯•ç­–ç•¥ \n",
    "3. æ¢ç´¢ gpt-4 æ”¯æŒçš„å¤šæ¨¡æ€å¯¹è¯åŠŸèƒ½\n",
    "4. äº†è§£ FunctionCall ä¸ ToolCalls\n",
    "5. ç†Ÿæ‚‰æœ‰çŠ¶æ€çš„å¯¹è¯å¼•æ“ `generate.ChatEngine`\n",
    "6. å­¦ä¹ é€‚ç”¨äºå¤§è§„æ¨¡è¯·æ±‚çš„è¡¥å…¨å¼•æ“ `generate.CompletionEngine`\n",
    "7. æ›´å¤šç²¾å½©å†…å®¹ç­‰ä½ å‘ç°...\n",
    "\n",
    "ğŸ¤– åŒæ—¶ï¼Œå¦‚æœä½ å¯¹ä»¥ä¸‹åº”ç”¨ç¤ºä¾‹æ„Ÿå…´è¶£ï¼Œè¯·ä¸è¦é”™è¿‡æˆ‘ä»¬çš„[åº”ç”¨ç¤ºä¾‹](https://github.com/wangyuxinwhy/generate/tree/main/examples)ï¼š\n",
    "1. ğŸš§ ä»£ç è§£é‡Šå™¨\n",
    "2. ğŸš§ å¤šæ¨¡æ€èŠå¤©æœºå™¨äºº\n",
    "3. ğŸš§ ç½‘ç»œæ–‡å­¦å¤šè§’è‰²é…éŸ³ä½“éªŒ\n",
    "\n",
    "ğŸ”§ æœ€åï¼Œå¦‚æœä½ æƒ³äº†è§£å¦‚ä½•é…ç½®å…¶ä»–å¤§æ¨¡å‹å¹³å°ï¼Œæˆ–è€…å…¨é¢ç³»ç»Ÿåœ°å­¦ä¹  `Generate`ï¼Œè¯·å‚è€ƒ [Generate æ–‡æ¡£](https://wangyuxinwhy.github.io/generate/)\n",
    "\n",
    "ç¥ä½ æ¢ç´¢æ„‰å¿«ï¼ğŸš€ğŸ’¡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
